{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4d2d71d4-901a-4a24-8044-f37b0251e7e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spotchaos.syntheticSignals as sp\n",
    "\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import matplotlib.animation as animation\n",
    "from matplotlib.animation import TimedAnimation\n",
    "from mpl_toolkits import mplot3d\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "import time\n",
    "import pickle\n",
    "\n",
    "import os\n",
    "from astropy.table import Table\n",
    "from astropy.timeseries import LombScargle\n",
    "from scipy.integrate import RK45, DOP853\n",
    "from scipy.stats import chi2, iqr\n",
    "from scipy.signal import argrelextrema, savgol_filter, find_peaks_cwt\n",
    "from scipy.spatial.distance import chebyshev\n",
    "from scipy.optimize import curve_fit\n",
    "\n",
    "from pytisean import tiseano, tiseanio\n",
    "\n",
    "from sklearn.neighbors import KDTree, BallTree\n",
    "from scipy.spatial import KDTree as scipyKDTree\n",
    "\n",
    "#%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a002f94c-ccec-44eb-a541-da15f9fb4cea",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Time series:\n",
    "# 0. White noise\n",
    "# 1. stationary GP time series\n",
    "# 2. Simple periodic\n",
    "# 3. KB88 R(t)\n",
    "# 4. Rossler x, y, z\n",
    "# 5. Transformed rossler u, v, w\n",
    "# 6. Lorenz x, y, z\n",
    "\n",
    "# and for each we have 3 baselines: TESS (perfect = 257062 data points), Kepler (perfect = 71422 data points), SPECULOOS (perfect = 44119 data points)\n",
    "#                   and 4 versions: perfect, gapless+noisy, gappy+noiseless, realistic\n",
    "# yielding 13*3*4 = 156 time series to analyze altogether. (But only 78 files, because the perfect and noisy versions are in the same file.)\n",
    "\n",
    "# Need to choose:\n",
    "# 1. time delay (Fraser & Swinney 1986)\n",
    "# 2. embedding dimension (Cao 1997)\n",
    "# and then calculate\n",
    "# 1. correlation dimension (Kurths & Herzel 1987; investigate pytisean too. Look into Thelier window.)\n",
    "# 2. Lyapunov spectrum (Wolf et al. 1985)\n",
    "# 3. Lyapunov dimension (Kaplan-Yorke conjecture; see Eckmann & Ruelle 1985 eq 4.11).\n",
    "\n",
    "# Expected results:\n",
    "# 0. White noise should have no good choice of time delay; mutual info as a function of delay time should be flat.\n",
    "# 1. Not sure!\n",
    "# 2. Simple periodic and KB88 R(t) results should be similar to KB88 figures 9 and 10.\n",
    "# 3. same\n",
    "# 4. Rossler x, y, and z should yield time delay ~ 1/4*rossler_qp and embedding dimension of 3. Rossler z results should be worse than x and y.\n",
    "# 5. Transformed Rossler u, v, and w should yield time delay ~1/4*transformed_rossler_qp and embedding dimension of 3. Variables should be about equally good.\n",
    "# 6. Lorenz x, y, and z should yield time delay ~1/4*lorenz_qp and embedding dimension of 3. z dimension will be insensitive to wing symmetry.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "813c4bcc-2b1b-4c51-90a3-60ba5f8fb174",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "folderpaths = ['0_gaussian_noise',\n",
    "               '1_gaussian_process',\n",
    "               '2_simple_periodic',\n",
    "               '3_KB88_r',\n",
    "               '4_rossler',\n",
    "               '5_transformed_rossler',\n",
    "               '6_lorenz']\n",
    "\n",
    "list_of_tsps = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4315bc06-ccd0-4094-a5f2-f12dc1427f6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class timeSeriesParams(object):\n",
    "    def __init__(self, filename, filepath, **kwargs):\n",
    "        self.filename = filename\n",
    "        self.filepath = filepath\n",
    "        self.QPmethod = None\n",
    "        self.QP = None\n",
    "        self.noisy_QP = None\n",
    "        self.bestTauIdx = None\n",
    "        self.noisy_bestTauIdx = None\n",
    "        self.sat_m = None\n",
    "        self.noisy_sat_m = None\n",
    "\n",
    "        self.euclideanCq = None\n",
    "        self.noisy_euclideanCq = None\n",
    "        self.euclideanCq_unc = None\n",
    "        self.noisy_euclideanCq_unc = None\n",
    "        self.euclideanD2 = None\n",
    "        self.noisy_euclideanD2 = None\n",
    "\n",
    "        self.tiseanC2 = None\n",
    "        self.noisy_tiseanC2 = None\n",
    "        self.tiseanD2 = None\n",
    "        self.noisy_tiseanD2 = None\n",
    "        self.tiseanH2 = None\n",
    "        self.noisy_tiseanH2 = None\n",
    "\n",
    "        allowed_keys = [\"QPmethod\",\"QP\",\"noisy_QP\",\"bestTauIdx\",\"noisy_bestTauIdx\",\"sat_m\",\"noisy_sat_m\",\"euclideanCq\",\"noisy_euclideanCq\",\"euclideanD2\",\"noisy_euclideanD2\",\"tiseanC2\",\"noisy_tiseanC2\",\"tiseanD2\",\"noisy_tiseanD2\",\"tiseanH2\",\"noisy_tiseanH2\"]\n",
    "\t\t\n",
    "        self.__dict__.update((k,v) for k,v in kwargs.items() if k in allowed_keys)\n",
    "\t\t\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f24040c7-c736-460c-a877-96580380b193",
   "metadata": {},
   "outputs": [],
   "source": [
    "def timeSeriesPlot(tsp, savefig=False):\n",
    "    data = np.genfromtxt(tsp.filepath)\n",
    "\n",
    "    if \"0\" in tsp.filename:\n",
    "        ts = data[:,2]\n",
    "        noisy_ts = data[:,2]\n",
    "    else:\n",
    "        ts = data[:,1]\n",
    "        noisy_ts = data[:,2]\n",
    "\n",
    "    fig, axes = plt.subplots(3,1,figsize=(18,12))\n",
    "    axes[0].plot(data[:,0],ts,marker='.',ms=5,ls='-',color='k',mec='None',lw=0.5,alpha=0.1)\n",
    "    axes[1].errorbar(data[:,0],noisy_ts,yerr=data[:,3],marker='.',ms=5,ls='-',color='k',mec='None',capsize=0.,elinewidth=0.5,lw=0.5,alpha=0.1)\n",
    "    axes[2].errorbar(data[:,0],ts-noisy_ts,yerr=data[:,3],marker='.',ms=5,ls='-',color='k',mec='None',capsize=0.,elinewidth=0.5,lw=0.5,alpha=0.1)\n",
    "    for ax in axes:\n",
    "        ax.set_xlim(data[:,0][0]-0.5, data[:,0][-1]+0.5)\n",
    "\n",
    "    axes[0].set_ylabel(r\"perfect x(t)\",fontsize=14)\n",
    "    axes[1].set_ylabel(r\"noisy x(t)\",fontsize=14)\n",
    "    axes[2].set_ylabel(r\"residuals\",fontsize=14)\n",
    "    axes[2].set_xlabel(r\"$t$ [days]\",fontsize=14)\n",
    "    if savefig is True:\n",
    "        plt.savefig(\"./timeseriesPlots/{0}_timeseriesplot.png\".format(tsp.filename.split(\".txt\")[0]),bbox_inches=\"tight\")\n",
    "        plt.close()\n",
    "        \n",
    "    else:\n",
    "        plt.show()\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9827d90a-0763-4cd1-a75e-bf58c8b12545",
   "metadata": {},
   "outputs": [],
   "source": [
    "def delayPlot(tsp, savefig=False):\n",
    "    data = np.genfromtxt(tsp.filepath)\n",
    "\n",
    "    if \"0\" in tsp.filename:\n",
    "        ts = data[:,2]\n",
    "        noisy_ts = data[:,2]\n",
    "    else:\n",
    "        ts = data[:,1]\n",
    "        noisy_ts = data[:,2]\n",
    "        \n",
    "    fig, axes = plt.subplots(1,2,sharex=True,sharey=True,figsize=(12,6))\n",
    "    axes[0].plot(ts[:-tsp.bestTauIdx], ts[tsp.bestTauIdx:],marker='.',ms=5,ls='-',color='k',mec='None',lw=0.5,alpha=0.1)\n",
    "    axes[1].errorbar(noisy_ts[:-tsp.noisy_bestTauIdx], noisy_ts[tsp.noisy_bestTauIdx:],xerr=data[:,3][:-tsp.noisy_bestTauIdx],yerr=data[:,3][tsp.noisy_bestTauIdx:],marker='.',ms=5,ls='-',color='k',mec='None',capsize=0.,elinewidth=0.5,lw=0.5,alpha=0.01)\n",
    "    for ax in axes:\n",
    "        ax.set_xlabel(r\"$x(t)$\",fontsize=14)\n",
    "        ax.set_ylabel(r\"$x(t+\\tau)$\",fontsize=14)\n",
    "        ax.set_aspect(\"equal\")\n",
    "\n",
    "    if savefig is True:\n",
    "        plt.savefig(\"./delayPlots/{0}_delayplot.png\".format(tsp.filename.split(\".txt\")[0]),bbox_inches=\"tight\")\n",
    "        plt.close()\n",
    "    else:\n",
    "        plt.show()\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "26d1619b-66e1-4331-ab62-66f5a770aaab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def spaceTimePlot(tsp, truncateIdx=None, metric='chebyshev', savefig=False):\n",
    "\n",
    "    data = np.genfromtxt(tsp.filepath)\n",
    "\n",
    "    if \"0\" in tsp.filename:\n",
    "        ts = data[:,2]\n",
    "        noisy_ts = data[:,2]\n",
    "    else:\n",
    "        ts = data[:,1]\n",
    "        noisy_ts = data[:,2]\n",
    "\n",
    "    if tsp.sat_m is None:\n",
    "        tisean_sat_m = 10\n",
    "    else:\n",
    "        tisean_sat_m = tsp.sat_m\n",
    "    if tsp.noisy_sat_m is None:\n",
    "        tisean_noisy_sat_m = 10\n",
    "    else:\n",
    "        tisean_noisy_sat_m = tsp.noisy_sat_m\n",
    "\n",
    "    #shorten time series, for debugging/plotting\n",
    "    if truncateIdx is not None:\n",
    "        ts = ts[:truncateIdx]\n",
    "        noisy_ts = noisy_ts[:truncateIdx]\n",
    "        \n",
    "    stp = tiseanio(\"stp\",\n",
    "                    '-d',tsp.bestTauIdx,\n",
    "                    '-m',tisean_sat_m,\n",
    "                    '-c',1,\n",
    "                    '-t',500,\n",
    "                    silent=True,\n",
    "                    data=ts)\n",
    "    stp = stp[0]\n",
    "\n",
    "    noisy_stp = tiseanio(\"stp\",\n",
    "                    '-d',tsp.noisy_bestTauIdx,\n",
    "                    '-m',tisean_noisy_sat_m,\n",
    "                    '-c',1,\n",
    "                    '-t',500,\n",
    "                    silent=True,\n",
    "                    data=noisy_ts)\n",
    "    noisy_stp = noisy_stp[0]\n",
    "\n",
    "    delayMat = sp.delayMatrix(ts, tau=tsp.bestTauIdx, m=tisean_sat_m)\n",
    "    ball_tree = BallTree(delayMat, leaf_size=10, metric=metric)\n",
    "    (distances,indices) = ball_tree.query(delayMat, k=np.shape(delayMat)[0],return_distance=True)\n",
    "    distances = np.ravel(distances[:,1:])\n",
    "    indices = indices - np.atleast_2d(np.arange(np.shape(delayMat)[0])).T\n",
    "    indices = np.ravel(indices[:,1:])\n",
    "    # we don't want to plot each pair of points twice, so limit ourselves to the positive indices\n",
    "    distances = distances[indices >= 0]\n",
    "    indices = indices[indices >= 0]\n",
    "\n",
    "    noisy_delayMat = sp.delayMatrix(noisy_ts, tau=tsp.noisy_bestTauIdx, m=tisean_noisy_sat_m)\n",
    "    noisy_ball_tree = BallTree(noisy_delayMat, leaf_size=10, metric=metric)\n",
    "    (noisy_distances, noisy_indices) = noisy_ball_tree.query(noisy_delayMat, k=np.shape(noisy_delayMat)[0],return_distance=True)\n",
    "    noisy_distances = np.ravel(noisy_distances[:,1:])\n",
    "    noisy_indices = noisy_indices - np.atleast_2d(np.arange(np.shape(noisy_delayMat)[0])).T\n",
    "    noisy_indices = np.ravel(noisy_indices[:,1:])\n",
    "    noisy_distances = noisy_distances[noisy_indices >= 0]\n",
    "    noisy_indices = noisy_indices[noisy_indices >= 0]\n",
    "    \n",
    "    #make spatial separation vs time separation plots, cf Provenzale et al 1992\n",
    "    fig, axes = plt.subplots(1,2,sharey=True,figsize=(16,6))\n",
    "    axes[0].plot(indices, distances, 'k.', ms=1,alpha=0.1,label='My code, metric={0}'.format(metric))\n",
    "    axes[1].plot(noisy_indices, noisy_distances, 'k.',ms=1,alpha=0.1)\n",
    "\n",
    "    axes[0].plot(stp[:,0], stp[:,1],color='r',marker='.',linestyle='None',ms=1,label='TISEAN, metric=chebyshev')\n",
    "    axes[1].plot(noisy_stp[:,0], noisy_stp[:,1],color='r',marker='.',linestyle='None',ms=1)\n",
    "\n",
    "    \n",
    "    axes[0].axvline(tsp.bestTauIdx,color='b',lw=2,label=\"best tau = {0}\".format(tsp.bestTauIdx))\n",
    "    axes[0].axvline(5*tsp.bestTauIdx,color='g',lw=2,label=\"5*best tau\")\n",
    "    \n",
    "    axes[1].axvline(tsp.noisy_bestTauIdx,color='b',lw=2,label=\"best tau = {0}\".format(tsp.noisy_bestTauIdx))\n",
    "    axes[1].axvline(5*tsp.noisy_bestTauIdx,color='g',lw=2,label=\"5*best tau\")\n",
    "\n",
    "    axes[0].legend(loc=\"lower right\",fontsize=12)\n",
    "    axes[1].legend(loc=\"lower right\",fontsize=12)\n",
    "    \n",
    "    for ax in np.ravel(axes):\n",
    "        ax.set_xlabel(r\"separation in time [cadences]\",fontsize=12)\n",
    "        ax.set_ylabel(r\"separation in space [units of time series]\",fontsize=12)\n",
    "        ax.set_xlim(0,np.max(indices)/3)\n",
    "        #ax.set_yscale(\"log\")\n",
    "\n",
    "    axes[0].set_title(\"{0}, perfect\".format(tsp.filename.split(\".txt\")[0]))\n",
    "    axes[1].set_title(\"noisy\")\n",
    "\n",
    "    if savefig is True: \n",
    "        plt.savefig(\"./spacetimesepPlots/{0}_spacetimesep.png\".format(tsp.filename.split(\".txt\")[0]),bbox_inches=\"tight\")\n",
    "        plt.close()\n",
    "    else:\n",
    "        plt.show()\n",
    "        \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "142cddcf-7738-49e7-a94f-0f23be0e03d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def callAndSaveMyCq(rArr, tsp, mMax=10, timeCall=True, truncateIdx=None):\n",
    "    data = np.genfromtxt(tsp.filepath)\n",
    "\n",
    "    if \"0\" in tsp.filename:\n",
    "        ts = data[:,2]\n",
    "        noisy_ts = data[:,2]\n",
    "    else:\n",
    "        ts = data[:,1]\n",
    "        noisy_ts = data[:,2]\n",
    "\n",
    "    scaleMin = np.min(noisy_ts)\n",
    "    scaleRange = np.ptp(noisy_ts)\n",
    "\n",
    "    ts = (ts - scaleMin)/scaleRange\n",
    "    noisy_ts = (noisy_ts - scaleMin)/scaleRange\n",
    "    noisy_ts_err = data[:,3]/scaleRange\n",
    "\n",
    "    if truncateIdx is not None:\n",
    "        ts = ts[0:truncateIdx]\n",
    "        noisy_ts = noisy_ts[0:truncateIdx]\n",
    "\n",
    "    header_tosave = \"r\"\n",
    "    unc_header_tosave = \"r\"\n",
    "    for m in range(2,mMax+1):\n",
    "        header_tosave = header_tosave + \" C0m={0}\".format(m)\n",
    "        unc_header_tosave = unc_header_tosave + \" C0uncm={0}\".format(m)\n",
    "    for m in range(2,mMax+1):\n",
    "        header_tosave = header_tosave + \" C1m={0}\".format(m)\n",
    "        unc_header_tosave = unc_header_tosave + \" C1uncm={0}\".format(m)\n",
    "    for m in range(2,mMax+1):\n",
    "        header_tosave = header_tosave + \" C2m={0}\".format(m)\n",
    "        unc_header_tosave = unc_header_tosave + \" C2uncm={0}\".format(m)\n",
    "        \n",
    "    Cq_tosave = np.zeros((len(rArr),1+3*(mMax-1)))\n",
    "    Cq_unc_tosave = np.zeros((len(rArr),1+3*(mMax-1)))\n",
    "    Cq_tosave[:,0] = rArr\n",
    "    Cq_unc_tosave[:,0] = rArr\n",
    "\n",
    "    noisy_Cq_tosave = np.zeros((len(rArr),1+3*(mMax-1)))\n",
    "    noisy_Cq_unc_tosave = np.zeros((len(rArr),1+3*(mMax-1)))\n",
    "    noisy_Cq_tosave[:,0] = rArr\n",
    "    noisy_Cq_unc_tosave[:,0] = rArr\n",
    "\n",
    "    #for d2 calculation\n",
    "    logrArr = np.log10(rArr)\n",
    "    logrArr_int = (logrArr[0:-1] + logrArr[1:])/2.\n",
    "    rArr_int = 10**logrArr_int\n",
    "\n",
    "    d2_header_tosave = \"r\"\n",
    "    for m in range(2,mMax+1):\n",
    "        d2_header_tosave = d2_header_tosave + \" D2m={0}\".format(m)\n",
    "\n",
    "    D2_tosave = np.zeros((len(rArr_int),1+(mMax-1)))\n",
    "    D2_tosave[:,0] = rArr_int\n",
    "\n",
    "    noisy_D2_tosave = np.zeros((len(rArr_int),1+(mMax-1)))\n",
    "    noisy_D2_tosave[:,0] = rArr_int\n",
    "    \n",
    "    #fig, axes = plt.subplots(1,2,figsize=(16,6))\n",
    "    for m in range(2, mMax+1):\n",
    "        print(\"m is {0}\".format(m))\n",
    "        start_cq = time.time()\n",
    "    \n",
    "        C0, C1, C2, C0unc, C1unc, C2unc = sp.Cq(rArr, ts, tau=tsp.bestTauIdx, m=m, theilerWindow=tsp.bestTauIdx)\n",
    "        noisy_C0, noisy_C1, noisy_C2, noisy_C0unc, noisy_C1unc, noisy_C2unc = sp.Cq(rArr, noisy_ts, tau=tsp.noisy_bestTauIdx, m=m, theilerWindow=tsp.noisy_bestTauIdx)\n",
    "        \n",
    "        end_cq = time.time()\n",
    "        if timeCall is True:\n",
    "            print(\"Cq call took {0} minutes\".format(np.round((end_cq - start_cq)/60, 2)))\n",
    "\n",
    "        #np.save(\"./c2arrs/{0}_euclidean_nArr_m={1}.npy\".format(tsp.filename.split(\".txt\")[0],m), nArr)\n",
    "        #np.save(\"./c2arrs/{0}_noisy_euclidean_nArr_m={1}.npy\".format(tsp.filename.split(\".txt\")[0],m), noisy_nArr)\n",
    "\n",
    "        Cq_tosave[:, 1 + (m-2)] = C0\n",
    "        Cq_tosave[:, 1 + (mMax-1) + (m-2)] = C1\n",
    "        Cq_tosave[:, 1 + 2*(mMax-1) + (m-2)] = C2\n",
    "\n",
    "        Cq_unc_tosave[:, 1 + (m-2)] = C0unc\n",
    "        Cq_unc_tosave[:, 1 + (mMax-1) + (m-2)] = C1unc\n",
    "        Cq_unc_tosave[:, 1 + 2*(mMax-1) + (m-2)] = C2unc\n",
    "\n",
    "        noisy_Cq_tosave[:, 1 + (m-2)] = noisy_C0\n",
    "        noisy_Cq_tosave[:, 1 + (mMax-1) + (m-2)] = noisy_C1\n",
    "        noisy_Cq_tosave[:, 1 + 2*(mMax-1) + (m-2)] = noisy_C2\n",
    "        \n",
    "        noisy_Cq_unc_tosave[:, 1 + (m-2)] = noisy_C0unc\n",
    "        noisy_Cq_unc_tosave[:, 1 + (mMax-1) + (m-2)] = noisy_C1unc\n",
    "        noisy_Cq_unc_tosave[:, 1 + 2*(mMax-1) + (m-2)] = noisy_C2unc\n",
    "\n",
    "        D2_tosave[:, 1 + (m-2)] = (np.log10(C2[1:]) - np.log10(C2[0:-1]))/(logrArr[1] - logrArr[0])\n",
    "        noisy_D2_tosave[:, 1 + (m-2)] = (np.log10(noisy_C2[1:]) - np.log10(noisy_C2[0:-1]))/(logrArr[1] - logrArr[0])\n",
    "        #axes[0].plot(Cq_tosave[:,0], Cq_tosave[:, 1 + 2*(mMax-1) + (m-2)], marker='.',ls='None')\n",
    "        #axes[1].plot(D2_tosave[:,0], D2_tosave[:, 1 + (m-2)], marker='.',ls='None')\n",
    "    #axes[0].set_xscale(\"log\")\n",
    "    #axes[0].set_yscale(\"log\")\n",
    "    #axes[1].set_xscale(\"log\")\n",
    "    #plt.show()\n",
    "\n",
    "    np.savetxt(\"./c2arrs/{0}_euclideanCq.txt\".format(tsp.filename.split(\".txt\")[0]), Cq_tosave, fmt=\"%f\", header=header_tosave)\n",
    "    np.savetxt(\"./c2arrs/{0}_euclideanCq_unc.txt\".format(tsp.filename.split(\".txt\")[0]), Cq_unc_tosave, fmt=\"%f\", header=unc_header_tosave)\n",
    "    np.savetxt(\"./c2arrs/{0}_noisy_euclideanCq.txt\".format(tsp.filename.split(\".txt\")[0]), noisy_Cq_tosave,fmt=\"%f\", header=header_tosave)\n",
    "    np.savetxt(\"./c2arrs/{0}_noisy_euclideanCq_unc.txt\".format(tsp.filename.split(\".txt\")[0]), noisy_Cq_unc_tosave,fmt=\"%f\", header=unc_header_tosave)\n",
    "    \n",
    "    np.savetxt(\"./c2arrs/{0}_euclideanD2.txt\".format(tsp.filename.split(\".txt\")[0]), D2_tosave, fmt=\"%f\", header=d2_header_tosave)\n",
    "    np.savetxt(\"./c2arrs/{0}_noisy_euclideanD2.txt\".format(tsp.filename.split(\".txt\")[0]), noisy_D2_tosave,fmt=\"%f\", header=d2_header_tosave)\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b343dbe2-9f56-4ac3-8819-22f1732d72d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def callAndSaveTiseanC2(rArr, tsp, mMax=10, timeCall=True, truncateIdx=None):\n",
    "    data = np.genfromtxt(tsp.filepath)\n",
    "\n",
    "    if \"0\" in tsp.filename:\n",
    "        ts = data[:,2]\n",
    "        noisy_ts = data[:,2]\n",
    "    else:\n",
    "        ts = data[:,1]\n",
    "        noisy_ts = data[:,2]\n",
    "\n",
    "    scaleMin = np.min(noisy_ts)\n",
    "    scaleRange = np.ptp(noisy_ts)\n",
    "\n",
    "    ts = (ts - scaleMin)/scaleRange\n",
    "    noisy_ts = (noisy_ts - scaleMin)/scaleRange\n",
    "    noisy_ts_err = data[:,3]/scaleRange\n",
    "\n",
    "    if truncateIdx is not None:\n",
    "        ts = ts[0:truncateIdx]\n",
    "        noisy_ts = noisy_ts[0:truncateIdx]\n",
    "\n",
    "    start = time.time()\n",
    "    d2dict = sp.d2_tisean(timeSeries=ts,tau=tsp.bestTauIdx,mMax=mMax,rArr=rArr,thelier=tsp.bestTauIdx)\n",
    "    firstd2call = time.time()\n",
    "    noisy_d2dict = sp.d2_tisean(timeSeries=noisy_ts,tau=tsp.noisy_bestTauIdx,mMax=mMax,rArr=rArr,thelier=tsp.noisy_bestTauIdx)\n",
    "    noisyd2call = time.time()\n",
    "\n",
    "    if timeCall is True:\n",
    "        print(\"first d2 call took {0} seconds\".format(np.round(firstd2call-start,2)))\n",
    "        print(\"noisy d2 call took {0} seconds\".format(np.round(noisyd2call-firstd2call,2)))\n",
    "\n",
    "    #print(np.shape(d2dict[\"c2\"])) #Always has shape of (len(rArr) * Mmax, 2)\n",
    "    #print(np.shape(d2dict[\"d2\"])) #Has shape (itDepends, 2)\n",
    "    #print(np.shape(d2dict[\"h2\"])) #Has shape (itDepends+mMax, 2)\n",
    "\n",
    "    # TISEAN outputs the results for m=1...mMax all in the same array. Need to sort these out before saving.\n",
    "    #this is easy for the c2 array, because d2dict[\"c2\"] always has shape (len(rArr) * Mmax, 2)\n",
    "    c2_header_tosave = \"r\"\n",
    "    d2_header_tosave = \"r\"\n",
    "    h2_header_tosave = \"r\"\n",
    "    for m in range(1,mMax+1):\n",
    "        c2_header_tosave = c2_header_tosave + \" C2m={0}\".format(m)\n",
    "        d2_header_tosave = d2_header_tosave + \" D2m={0}\".format(m)\n",
    "        h2_header_tosave = h2_header_tosave + \" H2m={0}\".format(m)\n",
    "\n",
    "    c2_tosave = np.zeros((len(rArr), mMax+1))\n",
    "    c2_tosave[:,0] = d2dict[\"c2\"][0:len(rArr), 0][::-1]\n",
    "\n",
    "    noisy_c2_tosave = np.zeros((len(rArr), mMax+1))\n",
    "    noisy_c2_tosave[:,0] = noisy_d2dict[\"c2\"][0:len(rArr), 0][::-1]\n",
    "\n",
    "    for m in range(1, mMax+1):\n",
    "        c2_tosave[:,m] = d2dict[\"c2\"][(m-1)*len(rArr) : m*len(rArr), 1][::-1]\n",
    "        noisy_c2_tosave[:,m] = noisy_d2dict[\"c2\"][(m-1)*len(rArr) : m*len(rArr), 1][::-1]\n",
    "\n",
    "    np.savetxt(\"./c2arrs/{0}_tiseanC2.txt\".format(tsp.filename.split(\".txt\")[0]), c2_tosave, fmt=\"%f\", header=c2_header_tosave)\n",
    "    np.savetxt(\"./c2arrs/{0}_noisy_tiseanC2.txt\".format(tsp.filename.split(\".txt\")[0]), noisy_c2_tosave, fmt=\"%f\", header=c2_header_tosave)\n",
    "\n",
    "    #for the d2 and h2 arrays it's more complicated, because these arrays return results for larger and larger rMin as m increases\n",
    "    diff = (d2dict[\"d2\"][1:,0] - d2dict[\"d2\"][0:-1,0])\n",
    "    diff_mask = (diff > 0.5)\n",
    "    noisy_diff = (noisy_d2dict[\"d2\"][1:,0] - noisy_d2dict[\"d2\"][0:-1,0])\n",
    "    noisy_diff_mask = (noisy_diff > 0.5)\n",
    "\n",
    "    d2_m_switch_ind = np.arange(len(d2dict[\"d2\"][1:,0]))[diff_mask] + 1\n",
    "    d2_m_switch_ind = np.concatenate((np.atleast_1d(np.array((0))), d2_m_switch_ind, np.atleast_1d(np.array((len(d2dict[\"d2\"][:,0]))))))\n",
    "    h2_m_switch_ind = np.concatenate((np.atleast_1d(np.array((0))), d2_m_switch_ind[1:]+np.arange(1, len(d2_m_switch_ind)), np.atleast_1d(np.array((len(d2dict[\"h2\"][:,0]))))))\n",
    "    \n",
    "    noisy_d2_m_switch_ind = np.arange(len(noisy_d2dict[\"d2\"][1:,0]))[noisy_diff_mask] + 1\n",
    "    noisy_d2_m_switch_ind = np.concatenate((np.atleast_1d(np.array((0))), noisy_d2_m_switch_ind,np.atleast_1d(np.array((len(noisy_d2dict[\"d2\"][:,0]))))))\n",
    "    noisy_h2_m_switch_ind = np.concatenate((np.atleast_1d(np.array((0))), noisy_d2_m_switch_ind[1:]+np.arange(1, len(noisy_d2_m_switch_ind)), np.atleast_1d(np.array((len(noisy_d2dict[\"h2\"][:,0]))))))\n",
    "    \n",
    "    \n",
    "    d2_tosave = np.zeros((d2_m_switch_ind[1], mMax+1))\n",
    "    noisy_d2_tosave = np.zeros((noisy_d2_m_switch_ind[1], mMax+1))\n",
    "\n",
    "    d2_tosave[:,0] = d2dict[\"d2\"][d2_m_switch_ind[0]:d2_m_switch_ind[1],0][::-1]\n",
    "    noisy_d2_tosave[:,0] = noisy_d2dict[\"d2\"][noisy_d2_m_switch_ind[0]:noisy_d2_m_switch_ind[1],0][::-1]\n",
    "\n",
    "    h2_tosave = np.zeros((h2_m_switch_ind[1], mMax+1))\n",
    "    noisy_h2_tosave = np.zeros((noisy_h2_m_switch_ind[1], mMax+1))\n",
    "\n",
    "    h2_tosave[:,0] = d2dict[\"h2\"][h2_m_switch_ind[0]:h2_m_switch_ind[1],0][::-1]\n",
    "    noisy_h2_tosave[:,0] = noisy_d2dict[\"h2\"][noisy_h2_m_switch_ind[0]:noisy_h2_m_switch_ind[1],0][::-1]\n",
    "\n",
    "    for m in range(1, mMax+1):\n",
    "        d2_tosave[:,m] = np.nan\n",
    "        d2_toskip = len(rArr) - 1 - (d2_m_switch_ind[m] - d2_m_switch_ind[m-1])\n",
    "        d2_tosave[d2_toskip:,m] = d2dict[\"d2\"][d2_m_switch_ind[m-1]:d2_m_switch_ind[m],1][::-1]\n",
    "\n",
    "        h2_tosave[:,m] = np.nan\n",
    "        h2_toskip = len(rArr) - (h2_m_switch_ind[m] - h2_m_switch_ind[m-1])\n",
    "        h2_tosave[h2_toskip:,m] = d2dict[\"h2\"][h2_m_switch_ind[m-1]:h2_m_switch_ind[m],1][::-1]\n",
    "\n",
    "        noisy_d2_tosave[:,m] = np.nan\n",
    "        noisy_d2_toskip = len(rArr) - 1 - (noisy_d2_m_switch_ind[m] - noisy_d2_m_switch_ind[m-1])\n",
    "        noisy_d2_tosave[noisy_d2_toskip:,m] = noisy_d2dict[\"d2\"][noisy_d2_m_switch_ind[m-1]:noisy_d2_m_switch_ind[m],1][::-1]\n",
    "\n",
    "        noisy_h2_tosave[:,m] = np.nan\n",
    "        noisy_h2_toskip = len(rArr) - (noisy_h2_m_switch_ind[m] - noisy_h2_m_switch_ind[m-1])\n",
    "        noisy_h2_tosave[noisy_h2_toskip:,m] = noisy_d2dict[\"h2\"][noisy_h2_m_switch_ind[m-1]:noisy_h2_m_switch_ind[m],1][::-1]\n",
    "\n",
    "    np.savetxt(\"./c2arrs/{0}_tiseanD2.txt\".format(tsp.filename.split(\".txt\")[0]), d2_tosave, fmt=\"%f\", header=d2_header_tosave)\n",
    "    np.savetxt(\"./c2arrs/{0}_noisy_tiseanD2.txt\".format(tsp.filename.split(\".txt\")[0]), noisy_d2_tosave, fmt=\"%f\", header=d2_header_tosave)\n",
    "\n",
    "    np.savetxt(\"./c2arrs/{0}_tiseanH2.txt\".format(tsp.filename.split(\".txt\")[0]), h2_tosave, fmt=\"%f\", header=h2_header_tosave)\n",
    "    np.savetxt(\"./c2arrs/{0}_noisy_tiseanH2.txt\".format(tsp.filename.split(\".txt\")[0]), noisy_h2_tosave, fmt=\"%f\", header=h2_header_tosave)\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fdd5cb73-8c62-45bc-b3b2-c2010f0f91cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadMyCq(tsp):\n",
    "    euclideanCq = Table.read(\"./c2arrs/{0}_euclideanCq.txt\".format(tsp.filename.split(\".txt\")[0]),format=\"ascii\")\n",
    "    euclideanCq_unc = Table.read(\"./c2arrs/{0}_euclideanCq_unc.txt\".format(tsp.filename.split(\".txt\")[0]),format=\"ascii\")\n",
    "    noisy_euclideanCq = Table.read(\"./c2arrs/{0}_noisy_euclideanCq.txt\".format(tsp.filename.split(\".txt\")[0]),format=\"ascii\")\n",
    "    noisy_euclideanCq_unc = Table.read(\"./c2arrs/{0}_noisy_euclideanCq_unc.txt\".format(tsp.filename.split(\".txt\")[0]),format=\"ascii\")\n",
    "   \n",
    "    euclideanD2 = Table.read(\"./c2arrs/{0}_euclideanD2.txt\".format(tsp.filename.split(\".txt\")[0]),format=\"ascii\")\n",
    "    noisy_euclideanD2 = Table.read(\"./c2arrs/{0}_noisy_euclideanD2.txt\".format(tsp.filename.split(\".txt\")[0]),format=\"ascii\")    \n",
    "\n",
    "    return euclideanCq, euclideanCq_unc, noisy_euclideanCq, noisy_euclideanCq_unc, euclideanD2, noisy_euclideanD2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d514dd90-6e78-417d-a47a-8da67d8553e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadTiseanC2(tsp):\n",
    "    C2 = Table.read(\"./c2arrs/{0}_tiseanC2.txt\".format(tsp.filename.split(\".txt\")[0]),format=\"ascii\")\n",
    "    noisy_C2 = Table.read(\"./c2arrs/{0}_noisy_tiseanC2.txt\".format(tsp.filename.split(\".txt\")[0]),format=\"ascii\")\n",
    "\n",
    "    D2 = Table.read(\"./c2arrs/{0}_tiseanD2.txt\".format(tsp.filename.split(\".txt\")[0]),format=\"ascii\")\n",
    "    noisy_D2 = Table.read(\"./c2arrs/{0}_noisy_tiseanD2.txt\".format(tsp.filename.split(\".txt\")[0]),format=\"ascii\")\n",
    "\n",
    "    H2 = Table.read(\"./c2arrs/{0}_tiseanH2.txt\".format(tsp.filename.split(\".txt\")[0]),format=\"ascii\")\n",
    "    noisy_H2 = Table.read(\"./c2arrs/{0}_noisy_tiseanH2.txt\".format(tsp.filename.split(\".txt\")[0]),format=\"ascii\")\n",
    "    \n",
    "    return C2, noisy_C2, D2, noisy_D2, H2, noisy_H2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "03f9efa3-ef05-4798-8a4c-6cef92945a6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"true\" C2 values from Sprott & Rowlands 2000\n",
    "lorenz_C2_lower = 2.049-0.096\n",
    "lorenz_C2_upper = 2.049+0.096\n",
    "lorenz_KY = 2.062\n",
    "rossler_C2_lower = 1.986-0.078\n",
    "rossler_C2_upper = 1.986+0.078\n",
    "rossler_KY = 2.013\n",
    "\n",
    "def plotC2D2(tsp, mMax=10, savefig=False):\n",
    "    \"\"\"\n",
    "    assumes tsp object now has euclidean and TISEAN C2, D2, etc.\n",
    "    \"\"\"\n",
    "    fig, axes = plt.subplots(2,2,figsize=(12,8))\n",
    "\n",
    "    for m in range(2,mMax+1):\n",
    "        axes[0,0].plot(tsp.tiseanC2[\"r\"], tsp.tiseanC2[\"C2m={0}\".format(m)],ms=3,marker='.',c='#FF8585',ls='None')\n",
    "        axes[0,0].errorbar(tsp.euclideanCq[\"r\"], tsp.euclideanCq[\"C2m={0}\".format(m)],tsp.euclideanCq_unc[\"C2uncm={0}\".format(m)],ms=3,linestyle='None',elinewidth=1,capsize=0,marker='+',c='#9985FF')\n",
    "        \n",
    "        axes[0,1].plot(tsp.tiseanD2[\"r\"], tsp.tiseanD2[\"D2m={0}\".format(m)],ms=3,marker='.',c='#FF8585',ls='None')\n",
    "        axes[0,1].plot(tsp.euclideanD2[\"r\"], tsp.euclideanD2[\"D2m={0}\".format(m)],ms=3,marker='+',c='#9985FF',ls='None')\n",
    "\n",
    "        axes[1,0].plot(tsp.noisy_tiseanC2[\"r\"], tsp.noisy_tiseanC2[\"C2m={0}\".format(m)],ms=3,marker='.',c='#FF8585',ls='None')\n",
    "        axes[1,0].errorbar(tsp.noisy_euclideanCq[\"r\"], tsp.noisy_euclideanCq[\"C2m={0}\".format(m)],tsp.noisy_euclideanCq_unc[\"C2uncm={0}\".format(m)],ms=3,linestyle='None',elinewidth=1,capsize=0,marker='+',c='#9985FF')\n",
    "        \n",
    "        axes[1,1].plot(tsp.noisy_tiseanD2[\"r\"], tsp.noisy_tiseanD2[\"D2m={0}\".format(m)],ms=3,marker='.',c='#FF8585',ls='None')\n",
    "        axes[1,1].plot(tsp.noisy_euclideanD2[\"r\"], tsp.noisy_euclideanD2[\"D2m={0}\".format(m)],ms=3,marker='+',c='#9985FF',ls='None')\n",
    "\n",
    "    if tsp.sat_m is not None:\n",
    "        axes[0,0].plot(tsp.tiseanC2[\"r\"], tsp.tiseanC2[\"C2m={0}\".format(tsp.sat_m)], marker='.',ms=7,c='r',ls='None',label=\"TISEAN\")\n",
    "        axes[0,0].errorbar(tsp.euclideanCq[\"r\"], tsp.euclideanCq[\"C2m={0}\".format(tsp.sat_m)], tsp.euclideanCq_unc[\"C2uncm={0}\".format(tsp.sat_m)], marker='+',ms=7, c='b', ls='None',label=\"Euclidean\",elinewidth=1,capsize=0)\n",
    "\n",
    "        axes[0,1].plot(tsp.tiseanD2[\"r\"], tsp.tiseanD2[\"D2m={0}\".format(tsp.sat_m)],  marker='.',ms=7,c='r',ls='None')\n",
    "        axes[0,1].plot(tsp.euclideanD2[\"r\"], tsp.euclideanD2[\"D2m={0}\".format(tsp.sat_m)],  marker='+',ms=7, c='b', ls='None')\n",
    "\n",
    "    if tsp.noisy_sat_m is not None:\n",
    "        axes[1,0].plot(tsp.noisy_tiseanC2[\"r\"], tsp.noisy_tiseanC2[\"C2m={0}\".format(tsp.noisy_sat_m)],  marker='.',ms=7,c='r',ls='None')\n",
    "        axes[1,0].errorbar(tsp.noisy_euclideanCq[\"r\"], tsp.noisy_euclideanCq[\"C2m={0}\".format(tsp.noisy_sat_m)], tsp.noisy_euclideanCq_unc[\"C2uncm={0}\".format(tsp.noisy_sat_m)], marker='+',ms=7, c='b', ls='None',elinewidth=1,capsize=0)\n",
    "\n",
    "        axes[1,1].plot(tsp.noisy_tiseanD2[\"r\"], tsp.noisy_tiseanD2[\"D2m={0}\".format(tsp.noisy_sat_m)],  marker='.',ms=7,c='r',ls='None')\n",
    "        axes[1,1].plot(tsp.noisy_euclideanD2[\"r\"], tsp.noisy_euclideanD2[\"D2m={0}\".format(tsp.noisy_sat_m)],  marker='+',ms=7, c='b', ls='None')\n",
    "\n",
    "    for ax in axes[:,0]:\n",
    "        ax.set_xscale(\"log\")\n",
    "        ax.set_xlim(7.e-4, 1.5)\n",
    "        ax.set_yscale(\"log\")\n",
    "        ax.set_ylim(7.e-7, 1.5)\n",
    "        ax.set_ylabel(\"correlation sum\")\n",
    "\n",
    "    for ax in axes[:,1]:\n",
    "        ax.set_xscale(\"log\")\n",
    "        ax.set_xlim(7.e-4, 1.5)\n",
    "        ax.set_ylim(-0.5, 8)\n",
    "        ax.set_ylabel(\"correlation dimension\")\n",
    "        if \"4\" in tsp.filename or \"5\" in tsp.filename:\n",
    "            ax.axhline(rossler_KY, color='k',lw=0.5)\n",
    "            ax.fill_between(np.linspace(7.e-4, 1.5, 3), y1=rossler_C2_lower*np.ones(3),y2=rossler_C2_upper*np.ones(3), color='k',alpha=0.1)\n",
    "        elif \"6\" in tsp.filename:\n",
    "            ax.axhline(lorenz_KY, color='k',lw=0.5)\n",
    "            ax.fill_between(np.linspace(7.e-4, 1.5, 3), y1=lorenz_C2_lower*np.ones(3),y2=lorenz_C2_upper*np.ones(3), color='k',alpha=0.1)        \n",
    "    \n",
    "    axes[0,0].legend(loc=\"lower right\",fontsize=10)\n",
    "\n",
    "    axes[0,0].set_title(\"{0}, sat_m = {1}\".format(tsp.filename.split(\".txt\")[0], tsp.sat_m))\n",
    "    axes[1,0].set_title(\"noisy sat_m = {0}\".format(tsp.noisy_sat_m))\n",
    "\n",
    "    plt.subplots_adjust(hspace=0.2)\n",
    "\n",
    "    if savefig is True: \n",
    "        plt.savefig(\"./c2Plots/{0}_C2D2.png\".format(tsp.filename.split(\".txt\")[0]),bbox_inches=\"tight\")\n",
    "        plt.close()\n",
    "    else:\n",
    "        plt.show()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "468e3c6c-f709-4f24-9ec6-e4e6909f3853",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0_gaussianNoise_speculoos_perfect.pickle', '1_gaussianProcess_speculoos_perfect.pickle', '2_simplePeriodic_speculoos_perfect.pickle', '3_KB88r_speculoos_perfect.pickle', '4_rossler_x_speculoos_perfect.pickle', '4_rossler_y_speculoos_perfect.pickle', '4_rossler_z_speculoos_perfect.pickle', '5_transformed_rossler_x_speculoos_perfect.pickle', '5_transformed_rossler_y_speculoos_perfect.pickle', '5_transformed_rossler_z_speculoos_perfect.pickle', '6_lorenz_x_speculoos_perfect.pickle', '6_lorenz_y_speculoos_perfect.pickle', '6_lorenz_z_speculoos_perfect.pickle']\n"
     ]
    }
   ],
   "source": [
    "list_of_tsp_filenames = []\n",
    "\n",
    "files = os.scandir(\".\")\n",
    "for file in files:\n",
    "    if \".pickle\" in file.name:\n",
    "        list_of_tsp_filenames.append(file.name)\n",
    "list_of_tsp_filenames.sort()\n",
    "print(list_of_tsp_filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "34d6d704-1bc2-4577-8368-f0ab41592ab0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0_gaussianNoise_speculoos_perfect\n",
      "1_gaussianProcess_speculoos_perfect\n",
      "2_simplePeriodic_speculoos_perfect\n",
      "3_KB88r_speculoos_perfect\n",
      "4_rossler_x_speculoos_perfect\n",
      "4_rossler_y_speculoos_perfect\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4_rossler_z_speculoos_perfect\n",
      "5_transformed_rossler_x_speculoos_perfect\n",
      "5_transformed_rossler_y_speculoos_perfect\n",
      "5_transformed_rossler_z_speculoos_perfect\n",
      "6_lorenz_x_speculoos_perfect\n",
      "6_lorenz_y_speculoos_perfect\n",
      "6_lorenz_z_speculoos_perfect\n"
     ]
    }
   ],
   "source": [
    "# evenly log-spaced array of r values for c2, d2 calculation\n",
    "# the data are normalized to fall within the unit cube, so this only needs to range from 0 to 1\n",
    "min_r = 1.e-3\n",
    "max_r = 1\n",
    "logrArr = np.linspace(np.log10(min_r),np.log10(max_r),100)\n",
    "rArr = 10**logrArr\n",
    "\n",
    "for tsp_filename in list_of_tsp_filenames:\n",
    "    with open (tsp_filename, 'rb') as f:\n",
    "        tsp = pickle.load(f)\n",
    "        print(tsp.filename.split(\".txt\")[0])\n",
    "        #print(vars(tsp))\n",
    "        data = np.genfromtxt(tsp.filepath)\n",
    "\n",
    "        if \"0\" in tsp.filename:\n",
    "            ts = data[:,2]\n",
    "            noisy_ts = data[:,2]\n",
    "        else:\n",
    "            ts = data[:,1]\n",
    "            noisy_ts = data[:,2]\n",
    "        \n",
    "        #print(\"perfect tauIdx is {0}, noisy tauIdx is {1}\".format(tsp.bestTauIdx, tsp.noisy_bestTauIdx))\n",
    "        #print(\"sat_m is {0}, noisy_sat_m is {1}\".format(tsp.sat_m, tsp.noisy_sat_m))\n",
    "\n",
    "        #timeSeriesPlot(tsp,savefig=True)\n",
    "        #delayPlot(tsp,savefig=True)\n",
    "        #spaceTimePlot(tsp,metric='euclidean',truncateIdx=5000,savefig=True)\n",
    "\n",
    "        #print(\"original time series length is {0}\".format(len(ts)))\n",
    "        \n",
    "        # scale time series to be between 0 and 1. use the \"noisy\" scaling for both noisy *and* perfect, \n",
    "        #   because we want them to be consistent, but the d2 call relies on all values falling between 0 and 1.\n",
    "        scaleMin = np.min(noisy_ts)\n",
    "        scaleRange = np.ptp(noisy_ts)\n",
    "\n",
    "        ts = (ts - scaleMin)/scaleRange\n",
    "        noisy_ts = (noisy_ts - scaleMin)/scaleRange\n",
    "        noisy_ts_err = data[:,3]/scaleRange\n",
    "\n",
    "        #C0, C1, C2, D2 using a Euclidean distance metric\n",
    "        #callAndSaveMyCq(rArr, tsp, mMax=7, timeCall=True, truncateIdx=None)\n",
    "\n",
    "        #C2, D2, H2 using TISEAN (chebyshev distance metric)\n",
    "        #callAndSaveTiseanC2(rArr, tsp, mMax=7, timeCall=True, truncateIdx=None)\n",
    "        '''\n",
    "        #load C0, C1, C2, D2 using Euclidean distance metric\n",
    "        Cq, Cq_unc, noisy_Cq, noisy_Cq_unc, D2, noisy_D2 = loadMyCq(tsp)\n",
    "        tC2, noisy_tC2, tD2, noisy_tD2, tH2, noisy_tH2 = loadTiseanC2(tsp)\n",
    "    \n",
    "        tsp.euclideanCq = Cq\n",
    "        tsp.euclideanCq_unc = Cq_unc\n",
    "        tsp.noisy_euclideanCq = noisy_Cq\n",
    "        tsp.noisy_euclideanCq_unc = noisy_Cq_unc\n",
    "        tsp.euclideanD2 = D2\n",
    "        tsp.noisy_euclideanD2 = noisy_D2\n",
    "\n",
    "        tsp.tiseanC2 = tC2\n",
    "        tsp.noisy_tiseanC2 = noisy_tC2\n",
    "        tsp.tiseanD2 = tD2\n",
    "        tsp.noisy_tiseanD2 = noisy_tD2\n",
    "        tsp.tiseanH2 = tH2\n",
    "        tsp.noisy_tiseanH2 = noisy_tH2\n",
    "        \n",
    "        with open('{0}.pickle'.format(tsp.filename.split(\".txt\")[0]), 'wb') as f:\n",
    "             # Pickle the 'data' dictionary using the highest protocol available.\n",
    "            pickle.dump(tsp, f)\n",
    "        '''        \n",
    "\n",
    "        #use mMax=7 because of Takens' thm\n",
    "        plotC2D2(tsp, mMax=7,savefig=True)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75dcc443-beae-40e4-92c3-a1405ce8e22e",
   "metadata": {},
   "source": [
    "# Note that the below no longer works because I'm not saving the full number of neighbors of each point, was too expensive\n",
    "## Colormap delay diagrams by recovered dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6f5d4640-05fe-4804-9a45-43f3c324ee45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3_KB88r_speculoos_perfect.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/f8/fqd5scnj31n0br62dg8rnm2w0000gn/T/ipykernel_37088/161106567.py:56: RuntimeWarning: invalid value encountered in divide\n",
      "  params_C2, params_unc_C2 = sp.fitLinearRegime(rArr, nArr, C2)\n",
      "/var/folders/f8/fqd5scnj31n0br62dg8rnm2w0000gn/T/ipykernel_37088/161106567.py:56: RuntimeWarning: divide by zero encountered in log10\n",
      "  params_C2, params_unc_C2 = sp.fitLinearRegime(rArr, nArr, C2)\n",
      "/var/folders/f8/fqd5scnj31n0br62dg8rnm2w0000gn/T/ipykernel_37088/161106567.py:58: RuntimeWarning: divide by zero encountered in log10\n",
      "  params_dist, params_dist_1sigma = sp.powerLawSlopeDistribution(rArr, nArr)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4_rossler_y_speculoos_perfect.txt\n",
      "1_gaussianProcess_speculoos_perfect.txt\n",
      "5_transformed_rossler_z_speculoos_perfect.txt\n",
      "0_gaussianNoise_speculoos_perfect.txt\n",
      "4_rossler_x_speculoos_perfect.txt\n",
      "6_lorenz_z_speculoos_perfect.txt\n",
      "5_transformed_rossler_y_speculoos_perfect.txt\n",
      "6_lorenz_x_speculoos_perfect.txt\n",
      "2_simplePeriodic_speculoos_perfect.txt\n",
      "4_rossler_z_speculoos_perfect.txt\n",
      "6_lorenz_y_speculoos_perfect.txt\n",
      "5_transformed_rossler_x_speculoos_perfect.txt\n"
     ]
    }
   ],
   "source": [
    "for tsp in list_of_tsps:\n",
    "    print(tsp.filename)\n",
    "    data = np.genfromtxt(tsp.filepath)\n",
    "\n",
    "    if \"0\" in tsp.filename:\n",
    "        ts = data[:,2]\n",
    "        noisy_ts = data[:,2]\n",
    "    else:\n",
    "        ts = data[:,1]\n",
    "        noisy_ts = data[:,2]\n",
    "\n",
    "    #print(\"perfect tauIdx is {0}, noisy tauIdx is {1}\".format(tsp.bestTauIdx, tsp.noisy_bestTauIdx))\n",
    "    #print(\"sat_m is {0}, noisy sat_m is {1}\".format(tsp.sat_m, tsp.noisy_sat_m))\n",
    "\n",
    "    if tsp.sat_m is None:\n",
    "        tsp.sat_m = 10\n",
    "    if tsp.noisy_sat_m is None:\n",
    "        tsp.noisy_sat_m = 10\n",
    "\n",
    "    #print(\"original time series length is {0}\".format(len(ts)))\n",
    "\n",
    "            \n",
    "    # scale ts to be between 0 and 1\n",
    "    #ts = (ts - np.min(ts))/np.ptp(ts)\n",
    "    #noisy_ts = (noisy_ts - np.min(noisy_ts))/np.ptp(noisy_ts)\n",
    "\n",
    "    min_r = 1.e-3\n",
    "    max_r = 1\n",
    "    logrArr = np.linspace(np.log10(min_r),np.log10(max_r),100)\n",
    "    rArr = 10**logrArr\n",
    "    \n",
    "    C2 = np.load(\"./c2arrs/{0}_c2_norm0to1.npy\".format(tsp.filename.split(\".txt\")[0]))\n",
    "    noisy_C2 = np.load(\"./c2arrs/{0}_noisy_c2_norm0to1.npy\".format(tsp.filename.split(\".txt\")[0]))\n",
    "\n",
    "    nArr = np.load(\"./c2arrs/{0}_nArr_norm0to1.npy\".format(tsp.filename.split(\".txt\")[0]))\n",
    "    noisy_nArr = np.load(\"./c2arrs/{0}_noisy_nArr_norm0to1.npy\".format(tsp.filename.split(\".txt\")[0]))\n",
    "\n",
    "    delayMat = sp.delayMatrix(ts, tsp.bestTauIdx, tsp.sat_m)\n",
    "    \n",
    "    N = np.shape(nArr)[0]\n",
    "    medians = np.percentile(nArr, 50, axis=0)\n",
    "\n",
    "    # exclude values of r where the median of n(r) is <= 10./N . Cutoff is a little arbitrary but the idea is that these points don't have enough neighbors.\n",
    "    enoughNeighborsIdxs = np.arange(len(rArr))[medians > 10./N]\n",
    "    firstGood = enoughNeighborsIdxs[0]\n",
    "    \n",
    "    # exclude values of r where any n(r) are NaN. The time series is not long enough to populate all the neighbors of the points.\n",
    "    anyNans = [np.any(~np.isfinite(nArr[:,i])) for i in range(len(rArr))]\n",
    "    anyNans = np.array(anyNans)\n",
    "    nansIdxs = np.arange(len(rArr))[anyNans]\n",
    "    try:\n",
    "        lastGood = nansIdxs[0]\n",
    "    except IndexError:\n",
    "        lastGood = -1\n",
    "    \n",
    "    params_C2, params_unc_C2 = sp.fitLinearRegime(rArr, nArr, C2)\n",
    "    \n",
    "    params_dist, params_dist_1sigma = sp.powerLawSlopeDistribution(rArr, nArr)\n",
    "          \n",
    "    #print(np.shape(params_dist))\n",
    "    #print(np.shape(params_dist[:,0]))\n",
    "    m = tsp.sat_m\n",
    "    tau = tsp.bestTauIdx\n",
    "    \n",
    "    fig, axes = plt.subplots(m,1,figsize=(6, 6*(m-1)))\n",
    "    axes = np.atleast_1d(axes)\n",
    "    for j in range(1,m):\n",
    "        if \"0\" not in tsp.filename:\n",
    "            axes[m-1-j].plot(delayMat[:,0],delayMat[:,j],linestyle='-',color='k',lw=0.25,marker=\"None\",zorder=1)\n",
    "        im = axes[m-1-j].scatter(delayMat[:,0],delayMat[:,j],c=params_dist[:,0],s=2,cmap=\"magma\",linewidths=0,alpha=0.7,zorder=2)\n",
    "        \n",
    "        divider = make_axes_locatable(axes[m-1-j])\n",
    "        cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
    "        cb = plt.colorbar(im, cax=cax)\n",
    "        cb.set_label(label=r\"Power law slope fit to $n(x_i)$ vs. $r$\",fontsize=14)\n",
    "        \n",
    "        axes[m-1-j].set_ylabel(r\"$x_i + {0}\\tau$\".format(j),fontsize=14)\n",
    "    \n",
    "    axes[m-2].set_xlabel(r\"$x_i$\",fontsize=14)\n",
    "\n",
    "    if \"0\" not in tsp.filename:\n",
    "        axes[m-1].plot(np.arange(0,len(delayMat[:,0])), delayMat[:,0], 'k-',lw=0.25,zorder=1)\n",
    "    im = axes[m-1].scatter(np.arange(0,len(delayMat[:,0])), delayMat[:,0], c=params_dist[:,0],s=2,cmap=\"magma\",alpha=0.7,zorder=2)\n",
    "    divider = make_axes_locatable(axes[m-1])\n",
    "    cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
    "    cb = plt.colorbar(im, cax=cax)\n",
    "    cb.set_label(label=r\"Power law slope fit to $n(x_i)$ vs. $r$\",fontsize=14)\n",
    "    axes[m-1].set_ylabel(r\"$x_i$\",fontsize=14)\n",
    "    axes[m-1].set_xlabel(\"i\", fontsize=14)\n",
    "    \n",
    "    n_t = len(delayMat[:,0])//tau\n",
    "    \n",
    "    #for k in range(n_t+1):\n",
    "    #    axes[m-1].axvline(k*tau, color='k', ls=\"-\",lw=0.5)\n",
    "\n",
    "    for ax in axes[0:-1]:\n",
    "        ax.set_aspect(\"equal\")\n",
    "        \n",
    "    plt.subplots_adjust(hspace=0.2)\n",
    "    #plt.show()\n",
    "    plt.savefig(\"./delayPlots/{0}_delayplot_C2colormap.png\".format(tsp.filename.split(\".txt\")[0]),bbox_inches=\"tight\")\n",
    "    plt.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "584bff73-8d50-4f5b-921f-93ec4bb14b52",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
